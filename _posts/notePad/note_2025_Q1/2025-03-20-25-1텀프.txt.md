---
title: "[Note] 25-03-20 25-1텀프.txt"
categories: [Notepad, Daily]
tags: 
date: 2025-03-20 21:49:00 +0900
comments: false
---
---


■시스템 보안

- 5주차(4/3) (Temporal Memory Safety 관련)
Efficient Use-After-Free Prevention with Opportunistic Page-Level Sweeping (NDSS '24)


## 중간고사
 ▪ 2주차: software security
 ▪ 3주차: spatial memory safety
 ▪ 4주차: temporal memory safety
 ▪ 5주차: control hijacking attack #1
 ▪ 6주차: control hijacking attack #2
 ▪ 7주차: data only attack

## 기말고사
 ▪ 9주차: Memory Isolation Mechanisms
 ▪ 10주차: Hardware assisted software security
 ▪ 11주차: Hardware monitors for software security
 ▪ 12주차: Trusted Execution Environment
 ▪ 13주차: Embedded System Security
 ▪ 14주차: Binary-based software security

________________________________________________________________________________________

■산업 PBL

- 뭐, 발표한다고 했는데

________________________________________________________________________________________

■고급 컴퓨터 비전

## Text-guided image editing (5/19)
## 참고 리스트
- Prompt-to-Prompt Image Editing with Cross Attention Control, ICLR'23
- Zero-shot Image-to-Image Translation, SIGGRAPH'23
- InstructPix2Pix: Learning to Follow Image Editing Instructions, CVPR'23
- Plug-and-Play Diffusion Features for Text-Driven Image-to-Image translation, CVPR'23

##팀원 분과 연락해봐야 함


----------------------------------------
##매주 다른 학생들 발표 전(금요일)에,
- 총 4개의 논문에 대해 각 논문 당 하나 이상의 Discussion Points 작성
----------------------------------------
3주차. Self-supervised Learning

1. A Simple Framework for Contrastive Learning of Visual Representationss ICML'20
- Projection Head 구조를 이후 다른 논문에서도 사용하던데, SimCLR이 Projection Head를 명시적으로 개념화하고, 실험적으로 그 효과를 검증한 최초의 논문인 것 같습니다. 논문에서 projection head 없이는 성능이 급격히 떨어지는 것을 보인 만큼, representation의 질을 결정하는 필수 요소라고 보이는데, 이 구조에 대한 후속 연구가 있는지 궁금합니다.

2. Exploring Simple Siamese Representation Learning, CVPR'21
- SimSiam은 명시적인 Negative Sample 없이 Positive Pair 간의 유사도를 최대화하는 방식으로 학습을 진행하는데, 이는 명확한 Negative Sample이 없기 때문에 Feature Representation이 특정 패턴에 Overfitting될 가능성이 있을 것으로 보입니다. Stop-Gradient 기법과 Predictor MLP가, Feature 다양성을 보장할 수 있는가에 대한 의문이 있습니다.

3. Emerging Properties in Self-Supervised Vision Transformers, ICCV'21
- Contrastive Learning과 대조되는 Self-Distillation에 대해 소개하고 있는데, ViT 모델은 CNN보다 훨씬 많은 연산량이 필요하고, Self-Distillation 과정에서는 Teacher와 Student 모델을 동시에 학습해야 하므로 더 많은 GPU 리소스가 필요한 것으로 보입니다. Contrastive Learning을 사용하는 SSL 기법들과 비교했을 때, Computational Efficiency 측면에서 얼마나 실용적인지? 또한 관련하여 진행된 최적화 연구는 어떤게 있는지 궁금합니다.

4. Masked Autoencoders Are Scalable Vision Learners, CVPR'22
- 논문에서 사용하는 랜덤 마스킹은 제일 단순한 baseline이지 않을까 하는 생각이 듭니다. 마스킹의 목표가 global feature를 학습하기 위해서라면, 의미를 많이 포함하는 영역을 지우는 등 더 좋은 마스킹 전략이 있지 않을지, 또는 downstream task에 따라 다른 전략을 적용하면 어떨지 궁금합니다.

----------------------------------------




















