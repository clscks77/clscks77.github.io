---
title: "[Note] 25-01-23 퍼징 공부_코드커버리지.txt"
categories: [Notepad, Daily]
tags: 
date: 2025-01-23 21:49:00 +0900
comments: false
---
---

## (*상위 분류) software 취약점 분석 갈래부터 알고싶음 

- software 취약점 분석 연구 갈래 (from. gpt) 
	- 퍼징(Fuzzing), 정적 분석(Static Analysis), 동적 분석(Dynamic Analysis), 하이브리드 분석(Hybrid Analysis)
	- AI와 머신러닝 활용(취약점 예측, 퍼징 최적화, 멀웨어 분석)
	- 특정 도메인 취약점 분석(IoT, 블록체인, 자동차 CAN)
	- 취약점 공격 시뮬레이션 및 방어 연구(=실제 시나리오를 재현하고 이에 대한 방어책을 마련하는 연구)(=샌드박스 기술, 익스플로잇 차단 기술)
	- 형식적 검증(Formal Verification), 리버스 엔지니어링(Reverse Engineering), 취약점 관리 시스템

- 소프트웨어 취약점 분석은 지능화와 자동화로 나아가고 있으며, 특히 퍼징 기술은 그 중심에 있다. (from. gpt) 

---------(공부가 필요하다 싶은 부분) ---------------------------------------------
### 퍼저 구조
- 그, 전에 봤는데 AFL++구조였던가?
- 설명: https://learn.darungrim.com/articles/fuzzing-code-coverage.html

### Intel PT?

### 코드 커버리지란, 
- 테스트 코드가 프로덕션 코드를 얼마나 실행했는지를 백분율로 나타내는 지표
- 코드의 커버리지 측정 기준은 여러가지가 있다.
- 함수(Function) 커버리지, 구문(Statement) 커버리지, 브랜치(Branch) 커버리지, 조건(Condition) 커버리지, 조건/결정(Condition/Decision) 커버리지
- 하지만 높은 커버리지가 테스트가 좋음을 보장해주지 않음. 커버리지 100%를 달성한다고 한들, 여전히 버그의 위험은 존재함

_____________________________________________

##[1] 퍼징 공부 ['21/01/05]: https://rninche01.tistory.com/entry/Fuzzing-%EA%B3%B5%EB%B6%80

- 무조건적으로 퍼징이 좋은 것은 아니다. 퍼징과 수동 테스트의 조합이 최적
	// 제발 레퍼를 달아줘~~~!!

- 익스 가능한 크래시를 발생하기도 하지만 언익스나 오탐 이런 것도 발생하기 때문에 
  유효한지 검사하기 위해 """검토 프로세스"""가 필요

- 테스트 케이스 생성 방법에 따른 퍼징 분류
	- Mutation Based Fuzzing (Dumb Fuzzing)
	--- American Fuzzy Lop (AFL): Coverage기반 mutation based fuzzer (dumb fuzzer) = 유전 알고리즘 사용
	- Generation Based Fuzzing (Smart Fuzzing)
	--- libFuzzer: coverage-guide in-process fuzzing engine = 한 프로세스에 대해서만 퍼징

- 테스트 케이스 생성기에 대한 지침 = Code Coverage ---> Guided fuzzing


_____________________________________________

##[2] 퍼징 기법 분류 - 뮤테이션 / 제너레이션: https://www.postype.com/##cpuu/post/589162

- 퍼징을 분류할 때 그 공격 기법이나 방식, 타겟 등등에 따라 다양한 종류로 구분할 수 있습니다.


_____________________________________________

##[3] 퍼징의 기초 - Code Coverage의 이해 ['23/03/05]:  https://learn.darungrim.com/articles/fuzzing-code-coverage.html

2006년 블랙햇에서 Shawn Embleton 등은 Sidewinder 발표를 통해서 코드 커버리지에 기반한 퍼징 방법론에 대해서 발표합니다. 
이후 2008년 Fuzz By Number라는 발표에서 찰리 밀러는 더 많은 코드 커버리지를 커버하는 샘플 셋을 가질 때에 
덤 퍼징 조차도 더 효율적으로 진행된다라는 실험 결과를 내어 놓습니다. 

이후 Code Coverage의 개념은 퍼징에 있어서 굉장히 중요한 개념으로 자리잡게 됩니다. 

#### Coverage Guided Fuzzing의 역사
2000년대 들어 많은 취약점 문제를 안고 있던 마이크로소프트 등의 회사에서는 
SAGE 등의 컨셉에 기반한 Code Coverage Guided Fuzzing의 개념을 일찍부터 사용하여 프러덕 시큐리티에 적용하고 있었습니다.
	// 마소의 SAGE
이후 마이크로소프트사는 이 서비스를 클라우드 형태의 Microsoft Security Risk Detection이라는 서비스로 공개

최근에는 대표적으로 AFL과 같은 퍼징 프레임워크의 발표와 함께 함께 리서쳐들도 Code Coverage Guided Fuzzing을 손쉽게 접할 수 있음
이후 AFL을 필두로 libFuzzer, Honggfuzz 아니면 커널 IOCTL들에 대한 퍼저인 Syzkaller 등의 다양한 Code Coverage Guided Fuzzer 들이 개발됨

_____________________________________________

##[4] Fuzzing에서의 Code Coverage 논쟁 ['20/10/14]: https://www.postype.com/##cpuu/post/8170641

그간 Fuzz test 논문들은 통상적으로 Coverage를 높였다는 점을 입증하기 위해 애를 써왔다. 
하지만 어떤 논문에서 "Coverage가 정말로 Bug find와 관련이 있는 거 맞음?"이라는 주장이 제기되었고, 
이후 Bug find와 관련성이 있는 coverage가 무엇인지에 대한 관심이 대두되었다. 


2018년에 발표된 Evaluating Fuzz Testing이라는 논문이 있다[1].
Fuzzing Paper 32개를 분석하여 각 저자들의 개별 실험 결과가 아닌, 통일된 조건에서 각각을 다시 평가(Evaluating)하고 비교 분석하였다.

실제로 AFLGo와 같은 경우 coverage를 높이는데 신경 쓰지 않는 대신 오류가 발생하기 쉬운 특정 부분을 더 집중적으로 공략함으로써 버그를 더 찾았다는 반례도 제시한다.

이 논문 쩐다: Be Sensitive and Collaborative: Analyzing Impact of Coverage Metrics in Greybox Fuzzing [USENIX '19]
퍼징에서 다양한 커버리지 요소들이 미치는 영향에 대한 (최초의) 체계적인 연구를 수행
Coverage-guided greybox fuzzing 상황에서 이론적으로 다양한 커버리지 메트릭을 비교하는 데 사용할 수 있는 
민감도(Sensitivity)의 개념을 공식적으로 제안

이 연구는 다양한 측정 항목의 조합을 통해 더 많은 Crash를 더 빠르게 찾을 수 있음을 보여주었으나, 
구체적으로 어떤 조합이 가장 좋은지는 찾지 못했으며 
그러므로 앞으로 그레이 박스 퍼징에 대한 더 많은 """커버리지 요소의 조합"""을 발견하는 연구를 자극하기를 바란다고 결론 맺음




---- Coverage 달성은 필요조건(Necessary)은 맞지만, 충분조건(not sufficient)은 아니라는 것



화이트 박스 퍼징
동적 심볼릭 실행(DSE)



Windows 커널은 2015년 [45] 이후 10개 이상의 주요 업데이트가 발표되는 등 매년 중요한 변화를 계속함에 따라 계속 성장하는 Windows 소프트웨어 생태계 전반에 퍼징의 범위를 확장하려면 커널에 구애받지 않는 (fully kernel-agnostic) 실행 메커니즘이 필요합니다.
-- no linux



