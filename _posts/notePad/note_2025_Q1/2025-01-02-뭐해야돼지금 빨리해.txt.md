---
title: "[Note] 25-01-02 뭐해야돼지금 빨리해.txt"
categories: [Notepad, Daily]
tags: 
date: 2025-01-02 21:49:00 +0900
comments: false
---
---

## column 뽑아내야


1. ---> 포렌식으로 넘어가는 이유
Explainability in Cryptocurrency/Blockchain Forensics
// "포렌식 분야에서 설명가능성을 강조한 논문들" ---> ★Explainability의 요구사항 도출
// 그 포렌식이 Cryptocurrency/Blockchain Forensics이어야 함 (or 이면 좋음?)


- XAI-CF -- Examining the Role of Explainable Artificial Intelligence in Cyber Forensics [Forensic Science International ‘24] ★

- Detecting anomalous cryptocurrency transactions: An AML/CFT application of machine learning-based forensics [‘23] ★

- Explainable AI for cybersecurity automation, intelligence and trustworthiness in digital twin: Methods, taxonomy, challenges and prospects [ICT Express ‘24]
	- 포렌식은 아닌데, 사이버 보안 맥락

- Digital forensics ai: evaluating, standardizing and optimizing digital evidence mining techniques ['22]

- Safeguarding the evidential value of forensic cryptocurrency investigations [Forensic Science International ‘20]




(XAI 요구사항)
National Institute of Standards and Technology [NIST] introduced four principles [40] and proposed that all XAI systems should adhere to these principles.

1. Explanation – 결과를 논리적으로 설명할 수 있는가?
	Self-Explainable -> 의사 결정 트리와 회귀 모델
	Post-Hoc Explainable ->  다른 소프트웨어 도구에 의해 렌더링
	- feature 중요도 점수, 규칙 세트, 히트맵 또는 자연어 표현을 생성함
2. Meaningful – 의미있는 설명인가?
	XAI 시스템은 맥락에 적합하고 의도한 사용자가 이해할 수 있는 의미 있는 정보를 제공해야 함
3. Explanation Accuracy – 결론에 도달하는 과정을 정확하게 설명하기 --> AI 알고리즘 및 시스템의 정확도와는 다름. 
	설명의 세부 수준 포함
4. Knowledge Limits – 지식의 한계를 모델이 인정하는가?
	잘모르겠는 애매한거를 막 던지지 않고 잘모르겠다 하는거(인듯)


1. Explanation – 결과를 논리적으로 설명할 수 있는가?
2. Meaningful – 의미있는 설명인가?
3. Explanation Accuracy – 결론에 도달하는 과정을 정확하게 설명하기
4. Knowledge Limits – 지식의 한계를 모델이 인정하는가?


-----------------------------------------------------------------------------------------------------------

2. ---> 모델-2 부분
MLD & Cryptocurrency/Blockchain Forensics에 적용되는 "XAI 논문들" 
또는 GNN을 메인 모델로 할거니까, GNN에 적용되는 "XAI 논문들"
// 여기서 뭐 도출해야 하냐 ---> ★문제점? my take-over? 

- Large Language Model XAI approach for illicit activity Investigation in Bitcoin [Neural Computing and Applications '24]
	-- 딱 내가 하고싶은 XAI

- Enhancing Illicit Activity Detection using XAI: A Multimodal Graph-LLM Framework [arxiv '23]
	-- 딱 내가 하고싶은 XAI (같은 사람)

- Explainability in Graph Neural Networks: A Taxonomic Survey [IEEE Transactions on Pattern Analysis and Machine Intelligence ‘22]


★Gite1 외[90] (2021)는 주가 예측을 위해 효율적인 머신러닝 기법, 특히 장단기 기억(LSTM)의 고급 조합을 활용합니다. 
이 논문에서는 모델의 의사 결정 과정에 대한 투명하고 의미 있는 인사이트를 얻기 위해 LIME과 함께 XAI 요소를 도입했습니다. 

-  The role of evaluations in reaching decisions using automated systems supporting forensic analysis [Forensic Science International '20]
	- General Forensics에 관해

- Atle2fc: Design of an augmented transfer learning model for explainable iot forensics using ensemble classification [ICAAIC '20]
	- 패턴 탐지?


(Explainable AI for cybersecurity automation, intelligence and trustworthiness in digital twin: Methods, taxonomy, challenges and prospects   '24)
Rawal et al. [27] , 2022	엑스	엑스	엑스	엑스	✓	엑스	✓	엑스	✓	✓	신뢰할 수 있는 XAI의 최근 발전 사항 발표
Ahmed et al. [29] , 2022	엑스	엑스	✓	✓	✓	엑스	*	엑스	✓	✓	산업 4.0에서 AI에서 XAI로의 연구 발표
Ibrahim et al. [13] , 2023	엑스	엑스	엑스	엑스	✓	엑스	✓	엑스	✓	✓	설명 가능한 CNN 중심 XAI 제시
Saeed et al. [30] , 2023	엑스	엑스	엑스	엑스	✓	엑스	✓	엑스	✓	✓	XAI에 대한 체계적인 메타조사를 제시



-----------------------------------------------------------------------------------------------------------

3.  ----> 모델-1 부분
Detecting anomalous cryptocurrency transactions (AML/CFT) 솔루션 논문

- Detecting anomalous cryptocurrency transactions: An AML/CFT application of machine learning-based forensics [‘23]
	- 그래프 합성 네트워크(GCN) 및 그래프 어텐션 네트워크(GAT)가 유망한 AML/CFT 솔루션임을 보여줌

- FraudLens: Graph Structural Learning for Bitcoin Illicit Activity Identification



-----------------------------------------------------------------------------------------------------------
## Cryptocurrency/Blockchain Forensics 개념 정리해서, 분류체계랑 같이 보여드려야

















