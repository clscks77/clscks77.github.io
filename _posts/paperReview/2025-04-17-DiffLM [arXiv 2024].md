---
title: "[Gen] DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models [arXiv 2025]"
categories: [PaperReview, GenerativeAI]
tags: [latent, llm, diffussion, synthetic_data]
date: 2025-04-17 20:41:07 +0900
comments: false
excerpt: "VAE + diffusion으로 latent space를 정의하고, 이를 LLM에 plug-and-play로 주입하여 controllable generation 실현"
--- 
---

<div class="tip-box tip-blue">
    <i class="fas fa-lightbulb tip-icon"></i>
    (나와의 유사점) ■ structured data, plug-and-play latent injection, latent space의 expressiveness <br>
    (집중할 부분) ■ VAE에서 latent space가 LLM에 어떻게 연결되는가? ■ diffusion module이 왜 필요한지?
</div>

- 오픈 리뷰 진짜 도움된다 <https://openreview.net/forum?id=fRmfDqZ2yq&utm_source=chatgpt.com>

## Open Review에서 지적한 문제점들

1. **Diffusion 도입의 필요성 미흡 (=핵심 아이디어의 정당성 부족)**
    - VAE 기반 latent space에 diffusion 모델을 결합하는 것이 중요하다고 주장하고 있지만, 왜 diffusion이 반드시 필요한지에 대한 실험적 혹은 이론적 근거가 약함.
    - 더 단순한 대안(Mixture of Gaussians prior, expressive priors 등)을 사용해도 비슷한 성능을 낼 수 있었을 가능성 지적
    - 즉, diffusion을 써야 하는 명확한 trade-off 분석, 선택의 정당성, 효과 비교가 부족

    > "새로운 기법을 제안할 때는 '왜 기존 방법이 안 되는가', '우리가 제안한 게 꼭 필요한가'에 대한  
	정밀한 실험이나 이론적 근거가 반드시 필요하다. 이 논문은 그 연결고리가 약했다."


2. **Ablation Study의 범위와 깊이 부족 (=실험)**
    - injector 모듈, VAE, diffusion 각각의 효과에 대한 정교한 분리 실험이 부족
        - diffusion 모델의 denoising network 구조나 timestep embedding에 따른 성능 차이 등

3. **강력한 baseline(modern LLMs)과의 비교 부족 (=실험)**
    - 비교 대상인 GReaT는 GPT-2 기반이고, TabSyn은 테이블 전용 diffusion 모델
    - GPT-4와 같은 현대적 LLM과의 prompt-based 방식과 비교가 부족하다고 지적

    > "논문이 제안하는 방법이 실제로 기존 강력한 방법보다 나은지를 검증하지 못하면, novelty와 practicality가 약하다는 판단을 받게 된다."

4. **논문의 주장과 실험 간의 연결 부족**
    - 실험 결과는 인상적이나, 논문 본문에서 그것을 이론적·분석적으로 뒷받침하는 설명이 약함.

5. **관련 문헌 인용 및 비교 부족**
    - Diffusion + LLM/VAE 관련 기존 연구(Lovelace et al. 2022, Zhang et al. 2023 등)가 누락됨.
    - 해당 분야에서의 최근 연구들과의 관계 및 차별점을 명확히 설명하지 않은 점을 지적.

**전반적인 평가: 아이디어는 흥미롭지만, 설계 근거와 비교 실험 부족으로 reject**

---
## Open Review에서 언급된 강점들

1. **흥미롭고 실용적인 문제 설정**
    - LLM을 활용한 구조화된 텍스트(표, 코드 등)의 synthetic data generation이라는 주제는 현업 및 학계에서 매우 수요가 높은 분야
        - 특히, privacy-preserving, data augmentation, tool simulation 등의 다양한 응용 가능성이 있어 실용성 측면에서 높은 평가

    > "The paper addresses the significant and relevant application of generative models: generating high-quality synthetic textual and structural data, which is an important field to study."


2. **기존 LLM fine-tuning 기법의 한계를 정확히 짚고 있음**
    - 기존 LLM fine-tuning 방식(GReaT 등)이 catastrophic forgetting, 구조 불일치, 비용 문제 등의 단점을 가진다는 점을 잘 짚어냄.
        - 이러한 문제를 latent space 기반의 sampling 접근으로 해결하려는 시도는 분명한 기여.

    > "기존 fine-tuning 방식은 구조화된 데이터에 적합하지 않은 경우가 많고, 이 점을 명확히 지적하고 대안을 제시한 점은 좋은 방향 설정이다."

3. **Plug-and-Play 구조로 설계된 DiffLM Framework**
    - DiffLM은 LLM 자체를 변경하지 않고 VAE + Diffusion에서 latent를 뽑아 soft prompt로 삽입하는 구조를 갖고 있음.
    - 이는 기존 LLM의 지식과 능력을 유지하면서도 data generation을 가능하게 하는 점에서 모듈성(modularity), 범용성(generalizability) 측면의 장점으로 평가됨.


4. **Post-processing, Human Evaluation, DCR 등 신경 쓴 평가 방법**
    - 단순 자동 지표뿐 아니라 GPT-4 기반 평가, human preference test, DCR(Distance to Closest Record) 등 다양한 측면에서 데이터 품질을 평가하려 한 점.
    - 특히 tools domain에서 인간 평가 결과, 88%의 우위를 보였다는 점은 신뢰도 향상에 도움.

---

## 핵심 아이디어 요약

- DiffLM은 다음 세 가지 핵심 기술을 조합한 새로운 데이터 생성 프레임워크를 제안함:
    1. **Encoding Process (VAE Encoder):** Language Model이 VAE 인코더 역할을 할 수 있도록 원본 데이터의 latent 분포 학습
        - 디코더형(Decoder-only) GPT 계열의 LLM이 아님. 
        - Encoder-only(BERT) 또는 Encoder-Decoder(T5) 구조를 활용하는 Language Model임 
            - Transformer 기반 사전학습 모델 (예: BERT, T5) 같은 feature encoder 역할의 모델
        - structured 텍스트 데이터를 latent vector로 ‘압축(인코딩)하는 과정'이 학습된다는 의미
            - 이게 어떻게 되는거지?
    2. **Latent Space Modeling (Diffusion):** Diffusion MLP로 노이즈 제거 및 복원(예측) 학습
        - 단순한 Gaussian sampling 대신, 진짜 데이터 분포를 더 정확히 반영하는 정교한 latent space를 학습
    3. **Synthesizing Process (LLM Decoder + Feature Injection):** Align Latent vector space with LLM decoder
        - latent vector로부터 입력 텍스트 복원하는 Decoder는 Frozen Language Model 사용
        - plug-and-play 방식을 위해 Latent 정보를 soft prompt(=Prompt tuning)로 삽입

![DiffLM_Overview](\assets\img\paper\DiffLM_Overview.PNG)
_Figure 1: Overview of DiffLM_

*질문:*
- **노랑 박스(Diffusion Forward Process), 파랑 박스(Denoising Backward Prcess) 차이는?**
    - Denoising MLP (Diffusion 모델):  latent space 자체를 학습하는 구성요소
    - 노랑: Latent vector 𝑧0에 노이즈를 점진적으로 추가해서 데이터를 정규분포에 가깝게 퍼뜨림
    - 파랑: 노이즈가 있는 𝑧𝑡로부터 원래의 𝑧0를 예측/복원
        - Diffusion MLP가 𝜖을 예측하도록 학습

- **왜 Normal Distribution이어야 하는지?**
    - LLM은 샘플링된 𝑧를 받아야 하니까, 학습된 latent 공간이 구조적이고 잘 정리된 공간이어야 함

- **정확히 어느 부분이 plug-and-play 구조인건지?**
    - plug-and-play인 부분은 Latent Feature Injector 파트
        - Diffusion을 통해 학습된 𝑧0를 받아서 LLM이 이해할 수 있는 soft prompt token embedding으로 변환함
        - 별도의 fine-tuning 없이 LLM 입력 앞단에 붙여 사용 (= plug-and-play)

- **Latent Feature Injector가 이해가 잘 안됨**
    - Latent vector 𝑧0는 LLM이 이해할 수 있는 형태가 아니라는 점을 알고 있어야 함
        - LLM은 입력을 텍스트 기반으로 받음 → 즉, token embedding 공간에서만 잘 작동할 수 있음
        - 하지만 VAE나 Diffusion에서 얻은 𝑧0는 임의의 latent vector → 그대로는 쓸 수 없음
    - 그래서 Latent vector 𝑧0를 LLM 입력 공간(token embedding space)으로 변환해야 함
        - 이 논문에서는 이를 plug-and-play 방식으로 하기 위해 Prompt Tuning 방식 중의 하나인 soft prompt 사용
        - soft prompt으로 k개의 soft token embedding 생성 (=학습 가능한 가상의 Prompt Vector)
        - LLM은 이를 보고 데이터 생성을 유도 받음

- **그럼 결국 이 아키텍처에서 학습하는건?**
    - LM Encoder: 입력 structured text → latent 𝜇, 𝜎 추출
    - Diffusion MLP: 노이즈 제거, latent 분포 정교화
    - Latent Injector (MLP): latent 𝑧0 → soft prompt로 변환

- **soft prompt 외의 다른 방식은 또 어떤게 가능할까?**
    - fine-tuning 없이 task에 적응시켰다는 점이 soft prompt의 강점
    - 논문에서도 비교 대상으로 다룬 2가지 대안이 있음
        - **Memory Injection (a.k.a. Key-Value Injection)**
        - **Embedding Injection**
    - Latent vector를 LLM의 입력 흐름 중 어느 지점에 주입하는가로 구분 가능
        - Soft Prompt: LLM 입력 token sequence 가장 앞 (input embedding 이전)
            - LLM이 입력 초반부터 latent의 영향을 받게 함
        - Memory Injection: LLM 내부의 Attention Layer (Key-Value 저장소)
            - LLM이 self-attention에서 직접 latent vector를 참조함
        - Embedding Injection: token embedding 단계에서 직접 덧셈
             - 가장 단순하지만 정보가 희석됨. 위치 정보 없이 단일 벡터만 추가되기 때문에 성능이 낮음

---
## 내 연구 기준, 눈여겨 볼 요소

- **latent vector를 통해 LLM의 내부 생성을 외부에서 조정**하기 때문에 Prompt tuning 없이도 형식적/구조적인 데이터 생성 가능
    - 내 목적인 "전략적으로 다양한 시나리오를 생성하되, plausible하게 유지"하는 요구와 일치
- Latent space를 명시적으로 다룬다는 점
    - 기존 LLM은 latent를 내부적으로만 사용 (hidden state로만 존재)  
    - DiffLM은 latent representation을 모델 외부에서 생성 → 조작 → injection하는 구조
- VAE만 사용할 경우, latent space가 oversimplified되거나 expressive하지 못한다? (→ 살펴봐야 할 부분)
    - Diffusion을 latent space 위에서 학습함으로써, 더 다양한 생성이 가능하면서도 원본 분포를 잘 보존함
- LLM 구조 자체를 수정하지 않는 Plug-and-Play 구조 (→ 나도 이러고 싶어!)
    - 학습된 latent vector를 decoder의 초기 context에 붙이거나 soft-prompt로 넣는 방식 사용

![DiffLM_reviewPoint](\assets\img\paper\DiffLM_reviewPoint.png)
_DiffLM_reviewPoint_

| **구성 요소** | **DiffLM 방식** | **내 연구에 적용 시** |
|--------------|----------------|------------------------|
| **Encoder** | VAE | 시나리오의 구조를 latent vector로 encode |
| **Latent 모델** | Latent Diffusion | 전략 스타일 변화, obfuscation 다양성 확보 |
| **LLM** | Frozen decoder | LLaMA2를 기반으로 시나리오 생성 |
| **Control** | Latent vector 조작 | 전략 복잡도, chain-hop 수, fan-out 깊이 등 조절 가능 |
| **평가** | downstream task / structure metrics | 탐지 가능성, 전문가 리뷰, 시나리오 다양성 등으로 평가 |

- 자연어 기반 시나리오 → semantic vector
- Structure-aware encoder: 전략 요소들을 구조적으로 파싱 → 그래프형 encoder (e.g., GCN, T5-based 구조화 입력)
- 시나리오를 latent vector로 압축하고 다시 reconstruct 가능하게 학습
  - 학습된 latent space는 전략 간 semantic 유사도 또는 구조 유사도를 반영
- 전략 유형별 Parameter화 (Diversity Control)

---

## 2. RELATED WORKS

### 2.1 Large Language Models in Data Synthesis.

LLM의 자연어 생성 능력은 향상됨에 따라 이를 데이터 증강(data augmentation)에 활용하려는 시도가 활발해짐
- 텍스트 분류 (Text Classification): Ye et al. (2022a), Li et al. (2023)
- 정보 추출 (Information Extraction): Tang et al. (2023), Josifoski et al. (2023)
- 표형 데이터 생성 (Tabular Generation): Borisov et al. (2023), Xu et al. (2024)

데이터 합성을 위한 언어 모델을 fine-tuning하려는 여러 연구가 시도됨
- Anaby-Tavor et al. (2020); Kumar et al. (2020); Dinh et al. (2022); Borisov et al. (2023); Xu et al. (2024);
- 소량의 골드 데이터에 대해 LLM을 미세 조정한 다음, 다양한 샘플링 방법을 사용하여 데이터를 생성함

하지만 Veselovsky et al. (2023)는 LLM 기반 생성물이 실제 데이터 분포와 괴리(Distribution Shift)를 보인다고 지적함
- 이는 학습 모델이 현실을 반영하지 못하는 synthetic data를 학습하게 되는 문제를 야기함


### 2.2 Latent Variable Models in Text Generation.

Latent Variable Model (LVM; 잠재변수모델)은 이미지 생성 분야에서 큰 성과를 보임
- Yu et al. (2022); Gu et al. (2022); Luo et al. (2023); Gulrajani et al. (2017)
  
특히 잠재 확산 모델은 데이터 공간이 아닌 잠재 공간에서 확산 과정을 수행하여 생성 품질과 계산 효율성 간의 균형을 최적화함 
- DALL-E (Betker et al., 2023), Stable Diffusion (Rombach et al., 2022)
  
NLP 분야에서도 latent space를 활용하는 시도가 있었음  
문장 표현, 텍스트 스타일 전송, 데이터 세트 증강 등의 작업을 수행하기 위해 잠재 공간을 언어 모델과 결합하려는 시도
- (Wiseman et al., 2018; Ding &Gimpel, 2019; Li et al., 2022; Gu et al., 2023; Borisov et al., 2023)

일부 연구에서는 보조 모듈을 사용하여 사전 학습된 언어 모델의 출력을 조정하는 것을 목표로, **plug-and-play controllable generation을 위해 diffusion을 사용하는 방법을 모색함**
- (Li et al., 2022; Gong et al., 2023)

**본 논문에서는 구조화된 데이터 합성이라는 더 어려운 시나리오를 다루고, ★잠재 지식 주입(latent knowledge injection)의 여러 방법을 철저히 조사함**

---

## 3. METHODOLOGY


### 3.1 PROBLEM FORMULATION

### 3.2 VAE-BASED REPRESENTATION LEARNING

### 3.3 LATENT SPACE DENOISING

### 3.4 LATENT FEATURE INJECTION


---

## 4 EXPERIMENTS


### 4.1 TABULARDATAGENERATION

### 4.2 CODE GENERATION

### 4.3 TOOL GENERATION

---

## 5 ANALYSIS

### 5.1 ABLATION STUDY

### 5.2 TRAININGDATAPLAGIARISM

### 5.3 VISUALIZATION

---

## 6 CONCLUSION


